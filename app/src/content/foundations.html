<main>
<section id="data-categories">
<h1>2. What data do platforms collect?</h1>
<p>
            Very large online platforms collect an enormous amount of data to keep their services running and to optimize the
            experience for users and advertisers. New employees often spend months learning the warehouse simply so they can find
            the right tables. This section reproduces the full text of the EDMO report so you can build the same intuition. Use it
            as a glossary: when a platform representative mentions “observed behavior” or “inferred scores,” you will know exactly
            what they mean and how the data are captured.
          </p>
<p>
            Six broad categories encompass the majority of fields held by VLOPSEs: information people provide directly, data
            collected from their devices, records of behavior, signals coming from other users, inferences generated by machine
            learning, and data purchased or collected from outside the platform. The tables below detail each family, replicating
            the report’s examples so you can see the breadth of possible fields.
          </p>
</section>
<section class="section" id="category-reference">
<h2>2.1 Data category reference</h2>
<p>
            Each category mixes qualitative and quantitative variables. The same person might have hundreds of rows describing
            their actions over time, alongside a handful of descriptive attributes such as account creation date. Use the table to
            map the vocabulary used by platforms to the kinds of questions you want to investigate.
          </p>
<div class="table-wrapper">
<table>
<thead>
<tr>
<th>Category</th>
<th>Examples of variables</th>
<th>Why platforms collect it</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>User provided</strong></td>
<td>
                    Names, email addresses, profile bios, pronouns, languages, birthdays, devices used, professional or creator
                    categories selected during onboarding.
                  </td>
<td>
                    Establish accounts, customize experiences, comply with advertising disclosure rules, and support safety teams
                    when authenticating users.
                  </td>
</tr>
<tr>
<td><strong>Extracted</strong></td>
<td>
                    IP addresses, GPS coordinates, device identifiers, browser fingerprints, overlap with other household devices,
                    and inferred country or region from connection metadata.
                  </td>
<td>
                    Detect suspicious access, enforce localization (e.g., content licensing), and surface context-sensitive
                    features like language defaults or regional policies.
                  </td>
</tr>
<tr>
<td><strong>Observed behavior</strong></td>
<td>
                    Session starts, watch time, click-throughs, scroll depth, reactions, shares, saves, search queries, ad
                    impressions, and time spent on each experience.
                  </td>
<td>
                    Power recommendation algorithms, highlight trending content, measure feature adoption, and identify potential
                    harms such as brigading or brigaded targets.
                  </td>
</tr>
<tr>
<td><strong>Signals from other users</strong></td>
<td>
                    Reports and appeals, block events, friend or follow requests, comments on profiles, and ratings provided by
                    trusted flaggers or community moderators.
                  </td>
<td>
                    Evaluate trust and safety workflows, assess quality of experience for vulnerable communities, and understand
                    how misinformation propagates across networks.
                  </td>
</tr>
<tr>
<td><strong>Inferred</strong></td>
<td>
                    Risk scores, predicted interests, estimated income brackets, authenticity likelihood, quality ratings for
                    media entities, and probabilities that content violates policy.
                  </td>
<td>
                    Feed ranking, ad targeting, abuse prevention, and policy enforcement rely on these outputs—often generated by
                    large machine learning systems trained on historical labels.
                  </td>
</tr>
<tr>
<td><strong>Purchased or external</strong></td>
<td>
                    Data broker attributes such as property ownership, credit history segments, charitable donation history,
                    third-party web browsing logs, or manually curated authoritative source lists.
                  </td>
<td>
                    Augment sparse internal signals, validate identity, support political ad transparency, and improve recommender
                    coverage in markets with limited first-party data.
                  </td>
</tr>
</tbody>
</table>
</div>
<p class="table-note">
            Source: Platform Datasets: Challenges, Insights, and Examples for Researchers under Article 40 of the Digital Services
            Act (EDMO, 2025).
          </p>
</section>
<section class="section" id="additional-families">
<h2>2.2 Extended data families</h2>
<p>
            Beyond the headline categories, platforms maintain specialized tables for content objects, sessions, predictive model
            outputs, survey programs, and networks. The examples below mirror the supplemental spreadsheet referenced in the report
            so you can examine the granularity available when Article 40 access is granted.
          </p>
<div class="table-wrapper">
<table>
<thead>
<tr>
<th>Dataset family</th>
<th>Key entities</th>
<th>Illustrative fields</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>User-centric tables</strong></td>
<td>Accounts, devices, enforcement history</td>
<td>
                    Account creation time, verification status, linked phone/email, risk tier, country, consent for sensitive data,
                    time since last active session.
                  </td>
</tr>
<tr>
<td><strong>Content tables</strong></td>
<td>Posts, videos, comments, audio tracks</td>
<td>
                    Content ID, creation timestamp, media type, length, language detection, safety labels, distribution status,
                    visibility flags, fact-checking verdicts.
                  </td>
</tr>
<tr>
<td><strong>Session tables</strong></td>
<td>Logins, device state changes, navigation flows</td>
<td>
                    Session ID, login source, network quality, surfaces visited, dwell time per surface, experiment buckets, logout
                    reason, concurrency indicators.
                  </td>
</tr>
<tr>
<td><strong>Predictive model tables</strong></td>
<td>Risk scores, recommendations, quality predictions</td>
<td>
                    Model version, score value, threshold applied, label timestamp, evaluator confidence, time-to-decision,
                    downstream action taken.
                  </td>
</tr>
<tr>
<td><strong>Survey and research tables</strong></td>
<td>In-product surveys, diary studies, civic panels</td>
<td>
                    Survey question ID, sampling frame, response options, weighting factors, optional text answers, retention policy
                    for personally identifiable information.
                  </td>
</tr>
<tr>
<td><strong>Network tables</strong></td>
<td>Follower graphs, group membership, messaging ties</td>
<td>
                    Edge type, source and destination IDs, affinity score, reciprocity, group roles, moderation interventions,
                    cross-network overlap.
                  </td>
</tr>
</tbody>
</table>
</div>
</section>
<section class="section" id="catalog">
<h2>2.3 Interactive platform data catalog</h2>
<p>
            Use the catalog to explore which public and restricted datasets align with your project. All entries correspond to the
            transparency programs referenced in the report and reflect their status as of early 2025.
          </p>
<div class="filter-bar" id="catalog-filters">
<label>
              Platform
              <select id="filter-platform">
<option value="">All platforms</option>
</select>
</label>
<label>
              Category
              <select id="filter-category">
<option value="">All categories</option>
</select>
</label>
<label>
              Availability
              <select id="filter-availability">
<option value="">All access paths</option>
</select>
</label>
<label>
              Keyword search
              <input id="filter-search" placeholder="e.g. transparency report" type="text"/>
</label>
<button class="button secondary" id="export-csv" type="button">Download CSV</button>
</div>
<div aria-live="polite" class="alert" id="catalog-status" role="status">Loading catalog…</div>
<div class="table-wrapper">
<table hidden="" id="catalog-table">
<thead>
<tr>
<th>Platform</th>
<th>Category</th>
<th>Data element</th>
<th>Availability</th>
<th>Notes</th>
<th>Last updated</th>
</tr>
</thead>
<tbody></tbody>
</table>
</div>
</section>
<section class="section" id="supplemental">
<h2>2.4 Supplemental datasets</h2>
<p>
            The original report linked to a spreadsheet describing hundreds of individual data points. The tables below bring that
            reference material onto the website so you can browse, filter, and download it without leaving the primer. Select a tab
            to focus on user, content, session, predictive, survey, or network datasets.
          </p>
<div class="supplemental-controls">
<div class="supplemental-tabs" id="supplemental-tabs" role="tablist"></div>
<div class="supplemental-search">
<label for="supplemental-search-input">Search fields</label>
<input id="supplemental-search-input" placeholder="Filter by field name or description" type="text"/>
</div>
<button class="button secondary" id="supplemental-export" type="button">Download visible rows</button>
</div>
<div class="table-wrapper">
<table id="supplemental-table">
<thead>
<tr>
<th>Field</th>
<th>Description</th>
<th>Primary table</th>
<th>Access considerations</th>
<th>Source</th>
</tr>
</thead>
<tbody></tbody>
</table>
</div>
</section>
<section class="section" id="staying-current">
<h2>2.5 Staying current on data access</h2>
<p>
            Article 40 programs continue to evolve. These organizations monitor platform transparency and can help you stay ahead of
            schema changes or new application windows.
          </p>
<div class="card-grid">
<article class="card">
<h3>European Digital Media Observatory</h3>
<p>
                EDMO convenes regional task forces that surface new datasets, highlight research-ready cohorts, and document where
                access falls short of legal requirements.
              </p>
<p><a href="https://edmo.eu" rel="noreferrer" target="_blank">Visit EDMO ↗</a></p>
</article>
<article class="card">
<h3>Integrity Institute</h3>
<p>
                A network of former platform professionals who publish implementation guidance, including practical tips for
                navigating data-sharing agreements and making sense of platform-specific terminology.
              </p>
<p><a href="https://integrityinstitute.org" rel="noreferrer" target="_blank">Explore resources ↗</a></p>
</article>
<article class="card">
<h3>All Tech Is Human</h3>
<p>
                A community advancing responsible technology. Their convenings and newsletters surface new collaborations between
                researchers, civil society, and industry, with frequent coverage of transparency tooling.
              </p>
<p><a href="https://alltechishuman.org" rel="noreferrer" target="_blank">Join the community ↗</a></p>
</article>
</div>
</section>
<section class="section" id="programs">
<h2>2.6 Trusted access programs</h2>
<p>
            These programs act as gateways to non-public datasets. Review their cadence and scope before drafting Article 40
            requests so you can align your research timelines with platform refresh cycles.
          </p>
<div class="card-grid" id="access-programs"></div>
</section>
<div class="page-nav">
<a href="index.html">← Previous: Welcome</a>
<a href="api.html">Next: Setting up Article 40 APIs →</a>
</div>
</main>