<main>
  <section class="hero" id="introduction">
    <h1>Introduction</h1>
    <p>
      Very large online platforms and search engines (VLOPSEs) collect both an incredible amount and a wide variety of data that
      even newly hired employees can struggle with as they learn the internal data systems. The structure of the data—and the
      data warehouse that the companies use to store all their data—can vary from company to company. Some might be chaotic,
      with data stored in tables that employees organically produce over time, and some might be more standardized and
      structured with employees required to follow a strict framework. In either situation, it can still be a challenge to
      understand the potentially hundreds or thousands of tables that VLOPSEs maintain in their data warehouses.
    </p>
    <p>
      Given the role of online platforms in our lives, it is not surprising that civil society and research institutions recognize
      the importance of this data, and in particular how it can help us better understand the risks that online platforms can pose
      to people, societies, and democracies. This data can also tell us how effectively the company is managing and minimizing
      those risks. Researchers and civil societies need to have access to datasets, both historical and real time, for studying the
      scale, cause, and nature of risks from the platforms. They need to be able to monitor the information environment in real
      time, especially around critical societal events like elections.
    </p>
    <p>
      Article&nbsp;40 of the Digital Services Act (DSA) allows for significant researcher access to VLOPSE data, creating the
      opportunity to answer research questions surrounding the systemic risks outlined in the DSA. This primer equips researchers,
      investigators, journalists, and civil society partners with the understanding and tools necessary to make the most of that
      access for the public good.
    </p>
    <p>Specifically, this primer aims to:</p>
    <ol>
      <li>Describe what types of data VLOPSEs collect.</li>
      <li>Describe how these data are stored.</li>
      <li>Describe how these data are used.</li>
      <li>Provide examples of how that data can be used to answer questions.</li>
      <li>Review data access APIs from VLOPSEs.</li>
      <li>Provide examples of how researchers may map the available data to the risks delineated in the Digital Services Act and the Code of Practice.</li>
    </ol>
  </section>

  <section class="section" id="article-40">
    <h2>Article&nbsp;40 at a glance</h2>
    <p>
      Article&nbsp;40 obligates Very Large Online Platforms and Search Engines to provide qualified researchers with access to the
      datasets needed to evaluate systemic risks, mitigation efforts, and compliance with the Code of Practice on Disinformation.
      The Article formalizes a pathway for requesting data, establishes safeguards for privacy, and requires platforms to respond
      on clear timelines. Used well, this access enables independent verification of platform claims, early detection of emerging
      harms, and evidence-based policy debates.
    </p>
    <p>
      Inside companies, engineers rely on expansive warehouses that log the moment-by-moment behavior of billions of accounts.
      Article&nbsp;40 is a lever that lets outside experts peek behind that curtain. This primer prepares you to engage with
      platforms from a position of understanding, so that when access is granted you know exactly what to ask for and how to
      interpret what you receive.
    </p>
  </section>

  <section class="section" id="using-primer">
    <h2>How to use this primer</h2>
    <p>
      The chapters mirror the structure of the original EDMO report. Each page contains the full narrative text, extended explanations,
      concrete examples, and downloadable resources. You can read linearly—from the foundations of what data exist, to how platforms
      transform them, to practical workflows and comparative case studies—or jump to the sections most relevant to your investigation
      via the table of contents.
    </p>
    <div class="card-grid">
      <article class="card">
        <h3>Start with the data landscape</h3>
        <p>
          Section&nbsp;2 catalogues the six core data categories VLOPSEs collect and provides detailed examples drawn from internal documentation.
          It is designed to make opaque terminology feel concrete before you ever write a query.
        </p>
      </article>
      <article class="card">
        <h3>Understand how platforms think</h3>
        <p>
          Section&nbsp;3 explains fact tables, dimension tables, probabilistic scores, and how they relate. Visual walkthroughs illustrate how
          platform teams combine these ingredients to measure activity or detect risk.
        </p>
      </article>
      <article class="card">
        <h3>Practice with real workflows</h3>
        <p>
          Section&nbsp;4 introduces typical research questions, provides annotated SQL examples, and offers browser-based sandboxes seeded with
          synthetic data. You can safely experiment with joins, filters, and aggregations before touching sensitive datasets.
        </p>
      </article>
    </div>
  </section>

  <section class="section" id="audiences">
    <h2>Who this is for</h2>
    <p>
      The Platform Data Primer is written for anyone seeking clarity about social media and search data—academic researchers,
      investigative journalists, civil society analysts, platform integrity teams, and public-interest technologists. No prior
      experience building data warehouses is required. Where the original PDF assumed familiarity with internal tooling, the web
      version adds supporting context, definitions, and examples so newcomers can follow along without feeling overwhelmed.
    </p>
    <p>
      If you already work inside a platform, use these chapters to align cross-functional partners. If you are new to Article&nbsp;40, follow
      the navigation sequentially: learn what exists, explore how it is stored, and then practice the analytical moves that transform
      raw tables into evidence.
    </p>
  </section>
</main>
